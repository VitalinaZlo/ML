Код пишет в файл "volgait2024-semifinal-result-test.csv"

# Принцип работы кода
В своём коде я использую библиотеку Natasha для извлечения адресных компонентов и Pandas для работы с данными в формате CSV. Код включает в себя несколько функций, каждая из которых выполняет определённую задачу в процессе обработки данных. Код запускался в Visual Studio Code (Python 3.12.7).

### Natasha
Так как в ходе исследования библиотеки Natasha выяснилось, что Natasha в основном различает адреса с присутствием в тексте определенных якорей (таких как 'пос', 'ул.', 'дом' и т. п.), было принято решение модифицировать её внутренние правила. Был изменен файл addr.py (\.venv\Lib\site-packages\natasha\grammars\addr.py). Были объединены и удалены типы, которые не участвуют в определении адреса, а также расширены правила нахождения типа для типов 'посёлок', 'улица', 'дом' и 'корпус'.

Стоит заметить, что сейчас правила работают на основе полных адресов из файла 'volgait2024-semifinal-addresses.csv'. К тому же, решение является масштабируемым, потому что при необходимости можно внести данные из классификатора ГАР ФИАС.

### Классификатор адресов
Перед основным кодом мы также подготавливаем не только диспетчерские комментарии, но и файл 'volgait2024-semifinal-addresses.csv'. В нем мы отсекаем всё до 'Ульяновск г.' (включительно), так как классификатор в принципе для Ульяновска, а потом делим оставшиеся части адреса на три столбца. В первом столбце 'village' находятся все поселки, села и другие объекты (назовем их все поселениями), у которых есть свои улицы. Во втором столбце находятся поселения, у которых нет своих улиц, и собственно улицы (улицы, бульвары, проспекты и т. п.) либо города Ульяновска, либо поселений из первого столбца. В третьем находятся номера домов с корпусами, строениями и литерами.

Далее мы работаем именно с этим видом классификатора.


### О ходе работы
В поисках оптимального решения было перепробовано много библиотек. 
* Я пыталась дообучить модель RuBERT для классификации начала и конца адреса. Но даже текст, максимально обработанный регулярными выражениями, и размеченная тестовая выбора в 600 строк не показали результатов. Потом пыталась даже обучить RuBERT сразу вытаскивать УИДы, соотнося расчищенные адреса с их полными версиями, но это показало результаты ещё хуже;

* Также хотелось применить Pullenti, в конце концов, распознанные им адреса можно привязать к ГАР ФИАС (что скорее плюс, чем минус, при условии реальности исходных данных), но так как бесплатный (уже обработанный) классификатор у них есть только для Москвы (77 региона), а все остальные обработанные только в коммерческой продаже, такое решение работало неэффективно. Без привязки к ГАР ФИАС Pullenti точно так же, как и Natasha, слабо распознавал адреса без якорей. Попытавшись понять в каком формате оформлен бесплатный классификатор, я наткнулась на нечитаемые массивы строк. Смена кодировки не помогла, так что путем несложных размышления я пришла к выводу, что скорее всего, классификатор специально зашифрован, иначе бы продажа классификаторов других регионов не слишком прибыльна;

* Пока я изучала литературу о парсинге и моделях, работающих с адресами, параллельно с этим я совершенствовала свою система нормализации диспетчерского комментария. Я делала это регулярными выражениями и расчистила комментарии настолько, что из них с помощью простенького регулярного выражения довольно точно можно было извлечь адреса. Если честно, было даже несколько иронично узнать, что ваше первое коммерческое решение тоже основывалось на регулярных выражениях. Но в итоге в этом решении просто не нужны были элементы ИИ, хотя его точность была и вправду высока. Пришлось отказаться и от него;

* Мой выбор остановился на Natasha, так как её исходный код был ближе всего мне для понимания; Повозившись с типами, настроив их так, чтобы они не конфликтовали друг с другом, я выяснила, что правила Natasha не работают с пробелами (вернее, как только в тексте появляется пробел, последующие символы, видимо, становятся новым токеном, а контекст, например, токен сзади и токен спереди Natasha не считывает), поэтому, чтобы она не разделяла улицу, например, состоящую из двух и более слов, все пробелы было решено заменить на символ вертикальный черты '|'. Из основго


## Структура кода
1.  Импорт библиотек (re, csv, pandas, natasha);

2.  Функция подготовки текста. def normalize_text(text: str) -> str;

3. Функция для определения начала адреса. def is_beginning_of_address(_type:str) -> bool (вспомогательная к следующей функции);

4. Функция нахождение и получение типов частей адресов. def finding_address_types(text:str) -> list;

5. Функция упорядочивание адресов и нахождение их УИДов. def extracting_address(addresses:list, addresses_df:pd.DataFrame) -> list;

6. Загрузка файл с диспетчерскими комментариями;

7. Загрузка файла-классификатора и его подготовка к работе;

8. Создание файла 'volgait2024-semifinal-result.csv' и запись УИДов в него; 
    * Причем, для файла предусмотрена функция дозаписи с интересующей нас строки;


## Функции
1. normalize_text(text: str) -> str

    Эта функция нормализует входной текст, удаляя ненужные символы и пробелы, а также обрабатывая специальные случаи.

    Основные шаги:

    * Замена чет и нечет на специальные обозначения — знак Тильды (~) обозначает четные диапазоны номеров домов, а Звездочка (*) нечетные;
    * Удаление части текста после "БЕЗ ХВС" (в самом разном виде), если данная конструкция имеется в комментарии;
    * Удаление ненужных символов и множественных пробелов;
    * Добавление специального символа '|' (вертикальной черты) в начале и конце строки для дальнейшей обработки и замена на него всех пробелов;

2. is_beginning_of_address(_type: str) -> bool

    Эта вспомогательная функция определяет, является ли текущий тип адреса началом адреса (улицей или посёлком).

3. finding_address_types(text: str) -> list

    Функция извлекает типы частей адреса и их значения из нормализованного текста.

    Основные шаги:
    * Использует addr_extractor для нахождения адресов;
    * Создаёт список addresses, в который добавляются найденные адреса с их типами и значениями;
    * Обрабатывает текущий адрес и добавляет его в список, если он начинается с улицы или посёлка;

4. extracting_address(addresses: list, addresses_df: pd.DataFrame) -> list

    Эта функция принимает список адресов и DataFrame-классификатор с полными адресами, чтобы извлечь УИДы.

    Основные шаги:
    * Инициализация списка houses_uuids для хранения найденных УИДов;
    * Итерация по адресам и извлечение значений для поселков, улиц и номеров домов.
    * Посёлки и улиц не обрабатываются, только знак '|' обратно заменяется на пробелы, а потом они добавляются в соответствующие переменные;
    * Номера домов и корпуса подвергаются дополнительной обработке. Если распознанный номер — это диазон, то в переменную для записи домов с помощью range записываются все номера домов от начала диапазона до его конца (включительно).
        * При этом, если номере дома с диапазоном присутствует литера, то сохраняются как все числа из диапазона без дроби, так и все числа из диапазона с литерой на конце;
        * Если же в номере дома с диапазоном присутствует символ '/', то сохраняются как все числа из диапазона без дроби, так и все числа из диапазона с числом-дробью;
        * Если в конце диапазона находится символ Тильды (~), то из диапазона сохраняются только четные числа;
        * Если же в конце находится символ Звездочки (*), то из диапазона сохраняются только нечетные числа;
    * Поиск соответствующих УИДов в DataFrame addresses_df и добавление их в список houses_uuids.